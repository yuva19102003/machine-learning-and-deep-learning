{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trained_model():\n",
    "    data = pd.read_csv('test.csv')\n",
    "    model = LinearRegression()\n",
    "    model.fit(data[['math']], data.cs)\n",
    "    return model.coef_, model.intercept_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y):\n",
    "\n",
    "    m = 0\n",
    "    b = 0\n",
    "\n",
    "    iterations = 1000000\n",
    "    n = len(x)\n",
    "    learning_rate = 0.1\n",
    "    cost_previous = 0\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        y_i = m*x + b\n",
    "        cost = (1/n)*sum([value**2 for value in (y-y_i)])\n",
    "        \n",
    "\n",
    "        md = -(2/n)*sum(x*(y-y_i))\n",
    "        bd = -(2/n)*sum(y-y_i)\n",
    "\n",
    "        m = m - learning_rate*md\n",
    "        b = b - learning_rate*bd\n",
    "\n",
    "        if math.isclose(cost, cost_previous, rel_tol=1e-20):\n",
    "            break\n",
    "        cost_previous = cost\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"m = {}, b = {}, cost = {}, iteration = {}\".format(m, b, cost, i))\n",
    "\n",
    "    return m, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 989.1800000000002, b = 13.980000000000002, cost = 5199.1, iteration = 0\n",
      "m = 5.671204129572697e+32, b = 8.002556588265454e+30, cost = 1.7020801684605084e+63, iteration = 10\n",
      "m = 3.2548722321592856e+62, b = 4.5929045455451004e+60, cost = 5.6065712162725365e+122, iteration = 20\n",
      "m = 1.8680676987868888e+92, b = 2.6360041234099046e+90, cost = 1.8467779241894746e+182, iteration = 30\n",
      "m = 1.0721394507506933e+122, b = 1.512880938353867e+120, cost = 6.083198749664812e+241, iteration = 40\n",
      "m = 6.153326255801467e+151, b = 8.682872357095188e+149, cost = 2.0037767694328848e+301, iteration = 50\n",
      "Using gradient descent function: Coef = -5.209158142223593e+160, Intercept = -7.350569977368983e+158\n",
      "Using sklearn model: Coef = [1.01773624], Intercept = 1.9152193111569034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30720/3996971255.py:16: RuntimeWarning: overflow encountered in scalar power\n",
      "  cost = (1/n)*sum([value**2 for value in (y-y_i)])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "\n",
    "    df = pd.read_csv('test.csv')\n",
    "\n",
    "    x = np.array(df.math)\n",
    "    y = np.array(df.cs)\n",
    "\n",
    "\n",
    "    m, b = gradient_descent(x, y)\n",
    "    print(\"Using gradient descent function: Coef = {}, Intercept = {}\".format(m, b))\n",
    "    \n",
    "\n",
    "    m_model, b_model = trained_model()\n",
    "    print(\"Using sklearn model: Coef = {}, Intercept = {}\".format(m_model, b_model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
